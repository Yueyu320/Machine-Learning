{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46fd47ad-0a97-4d5a-a6c7-3a358a23b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21cd17a-60f4-49da-b36f-8da47e17b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12f47a-c69e-4675-b3f6-5592e5b839a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c50340-5611-4aa7-b562-96fd63850bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.normal(0, 1, size=X_new_ori.shape)\n",
    "X_new = X_new_ori + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094862d-745e-4724-b91a-941ce4e1eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "587fe984-54cc-46b1-aa83-30837dd96938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae44c8-539b-484f-aadb-61ba1e8bb50d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40629fda-03ae-4a16-b5f9-6de7ee7d3f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bp</th>\n",
       "      <th>Sg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Su</th>\n",
       "      <th>Rbc</th>\n",
       "      <th>Bu</th>\n",
       "      <th>Sc</th>\n",
       "      <th>Sod</th>\n",
       "      <th>Pot</th>\n",
       "      <th>Hemo</th>\n",
       "      <th>Wbcc</th>\n",
       "      <th>Rbcc</th>\n",
       "      <th>Htn</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.00000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.00000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75.956250</td>\n",
       "      <td>1.017750</td>\n",
       "      <td>0.99375</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.89375</td>\n",
       "      <td>55.386563</td>\n",
       "      <td>2.873625</td>\n",
       "      <td>137.464750</td>\n",
       "      <td>4.680781</td>\n",
       "      <td>12.589656</td>\n",
       "      <td>8422.937500</td>\n",
       "      <td>4.719031</td>\n",
       "      <td>0.352313</td>\n",
       "      <td>0.618750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.833242</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>1.25694</td>\n",
       "      <td>1.019745</td>\n",
       "      <td>0.30864</td>\n",
       "      <td>48.875895</td>\n",
       "      <td>5.424476</td>\n",
       "      <td>9.778089</td>\n",
       "      <td>3.125634</td>\n",
       "      <td>2.662750</td>\n",
       "      <td>2563.656577</td>\n",
       "      <td>0.815552</td>\n",
       "      <td>0.476909</td>\n",
       "      <td>0.486454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.015000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>6900.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>137.530000</td>\n",
       "      <td>4.630000</td>\n",
       "      <td>12.530000</td>\n",
       "      <td>8406.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.925000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>9400.000000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Bp          Sg         Al          Su        Rbc          Bu  \\\n",
       "count  320.000000  320.000000  320.00000  320.000000  320.00000  320.000000   \n",
       "mean    75.956250    1.017750    0.99375    0.384375    0.89375   55.386563   \n",
       "std     13.833242    0.005494    1.25694    1.019745    0.30864   48.875895   \n",
       "min     50.000000    1.005000    0.00000    0.000000    0.00000   10.000000   \n",
       "25%     70.000000    1.015000    0.00000    0.000000    1.00000   27.000000   \n",
       "50%     76.000000    1.020000    0.50000    0.000000    1.00000   42.000000   \n",
       "75%     80.000000    1.020000    2.00000    0.000000    1.00000   57.000000   \n",
       "max    180.000000    1.025000    5.00000    5.000000    1.00000  391.000000   \n",
       "\n",
       "               Sc         Sod         Pot        Hemo          Wbcc  \\\n",
       "count  320.000000  320.000000  320.000000  320.000000    320.000000   \n",
       "mean     2.873625  137.464750    4.680781   12.589656   8422.937500   \n",
       "std      5.424476    9.778089    3.125634    2.662750   2563.656577   \n",
       "min      0.400000    4.500000    2.500000    3.100000   2200.000000   \n",
       "25%      0.900000  135.000000    4.000000   10.900000   6900.000000   \n",
       "50%      1.350000  137.530000    4.630000   12.530000   8406.000000   \n",
       "75%      2.925000  140.250000    4.800000   14.700000   9400.000000   \n",
       "max     76.000000  163.000000   47.000000   17.800000  26400.000000   \n",
       "\n",
       "             Rbcc         Htn       Class  \n",
       "count  320.000000  320.000000  320.000000  \n",
       "mean     4.719031    0.352313    0.618750  \n",
       "std      0.815552    0.476909    0.486454  \n",
       "min      2.100000    0.000000    0.000000  \n",
       "25%      4.500000    0.000000    0.000000  \n",
       "50%      4.710000    0.000000    1.000000  \n",
       "75%      5.100000    1.000000    1.000000  \n",
       "max      8.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30814598-8ba6-4f19-9878-347bad4cacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Class']\n",
    "X_train = train.loc[:, train.columns!='Class']\n",
    "y_test = test['Class']\n",
    "X_test = test.loc[:, test.columns!='Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62faf9c5-f088-4174-9ca6-984558dfd512",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new2 = pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "64e0de1f-58bf-4388-8974-40f25ac8d18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgt = LogisticRegression(random_state=42, penalty='none')\n",
    "lgt.fit(X_new2, y_train)\n",
    "np.mean(lgt.predict(X_test_new) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60a9928a-7982-45d8-a2ef-340810c32754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(algo, X, Y, M, K, criteria):\n",
    "    \"\"\"\n",
    "    This function uses dropout method to train a predicted model that optimizes the specific criterion.\n",
    "    @param algo(required): A learning algorithm that takes X, Y as inputs and outputs a model \n",
    "    @param X(required): The matrix of indepdent/predictor variables\n",
    "    @param Y(required): The outcome variable\n",
    "    @param M(required): The number of Monte Carlo replicates\n",
    "    @param K(required): Number of CV folds for tuning hyperparameter\n",
    "    @param criteria(required): A criterion to be used to evaluate the method. \n",
    "    Can be either mean squared error (MSE) or mean absolute deviation (MAD)\n",
    "    @return: A predictive model that optimizes the specific criterion\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of phi values to be tuned\n",
    "    phi_list = np.arange(0, 1, 0.1)\n",
    "    cv_error = []\n",
    "    \n",
    "    for phi in phi_list:\n",
    "        # Create k folds for cross-validation\n",
    "        kf = KFold(n_splits = K, shuffle=True)\n",
    "        error = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "            \n",
    "            # Monte Carlo: expand original data M times to generate a new dataset \n",
    "            # (X will be modified later)\n",
    "            X_new_ori = np.repeat(X_train, M, axis=0)\n",
    "            Y_new = np.repeat(Y_train, M, axis=0)\n",
    "            \n",
    "            # Generate independent Bernoulli random variables Z\n",
    "            z = np.random.binomial(1, phi, size=X_new_ori.shape)\n",
    "            # Random Dropout for X\n",
    "            X_new = X_new_ori*z/(1-phi)\n",
    "            \n",
    "            # Fit input learning algorithm with new data\n",
    "            reg = algo(X_new, Y_new)\n",
    "            # Predict Y using X test\n",
    "            pred = reg.predict(X_test)\n",
    "            \n",
    "            # Calculate MSE/MAD using the model obtained above\n",
    "            if criteria == \"MSE\":\n",
    "                error.append(mean_squared_error(Y_test, pred))\n",
    "            elif criteria == \"MAD\":\n",
    "                error.append(mean_absolute_error(Y_test, pred))\n",
    "            # Raise error if input is not MSE or MAD\n",
    "            else:\n",
    "                raise ValueError('Please input either MSE or MAD!')\n",
    "        \n",
    "        cv_error.append(np.mean(error))\n",
    "    \n",
    "    # Find optimal phi value that has the smallest CV error\n",
    "    phi_opt = phi_list[np.argmin(cv_error)]\n",
    "    \n",
    "    # Use the optimal phi value to train the predicted model\n",
    "    X_new_ori = np.repeat(X, M, axis=0)\n",
    "    Y_new = np.repeat(Y, M, axis=0)\n",
    "    \n",
    "    z = np.random.binomial(1, phi_opt, size=X_new_ori.shape)\n",
    "    X_new = X_new_ori*z/(1-phi_opt)\n",
    "\n",
    "    reg = algo(X_new, Y_new)\n",
    "    \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30f0cde2-d657-4bb0-8964-b9c9c168df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgt_drop(X, Y):\n",
    "    return LogisticRegression(random_state=42, penalty='none').fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c00ad58-70af-4732-afe5-120cf693a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.values\n",
    "y = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9cc7b9f7-683c-44f5-b7cb-87e6a9d0982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.normal(0, 3, size=X.shape)\n",
    "X_new = X + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d111dada-8392-4934-9f3f-375c333826db",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = np.random.normal(0, 20, size=X_test.shape)\n",
    "X_test_new = X_test + z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f798b52d-a1e8-4b1f-996a-c81829422df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgt_drop_fit = dropout(lgt_drop, X_new, y, 100, 5, 'MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e64251d0-fdc5-4a4b-8479-8ddec1afa48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lgt_drop_fit.predict(X_test_new) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cfb46-6d27-4549-95ee-0d1eb4ed6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_up(algo, X, Y, M, K, criteria):\n",
    "    \"\"\"\n",
    "    This function uses dropout method to train a predicted model that optimizes the specific criterion.\n",
    "    @param algo(required): A learning algorithm that takes X, Y as inputs and outputs a model \n",
    "    @param X(required): The matrix of indepdent/predictor variables\n",
    "    @param Y(required): The outcome variable\n",
    "    @param M(required): The number of Monte Carlo replicates\n",
    "    @param K(required): Number of CV folds for tuning hyperparameter\n",
    "    @param criteria(required): A criterion to be used to evaluate the method. \n",
    "    Can be either mean squared error (MSE) or mean absolute deviation (MAD)\n",
    "    @return: A predictive model that optimizes the specific criterion\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of phi values to be tuned\n",
    "    # phi_list = np.arange(0, 1, 0.1)\n",
    "    # cv_error = []\n",
    "    \n",
    "    # for phi in phi_list:\n",
    "        # Create k folds for cross-validation\n",
    "        # kf = KFold(n_splits = K, shuffle=True)\n",
    "        # error = []\n",
    "        # for train_index, test_index in kf.split(X):\n",
    "        #     X_train, X_test = X[train_index], X[test_index]\n",
    "        #     Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "            \n",
    "            # Monte Carlo: expand original data M times to generate a new dataset \n",
    "            # (X will be modified later)\n",
    "            X_new_ori = np.repeat(X, M, axis=0)\n",
    "            Y_new = np.repeat(Y, M, axis=0)\n",
    "            \n",
    "            # Generate independent Bernoulli random variables Z\n",
    "            center = np.mean(X_new_ori, axis=0)\n",
    "            dist = [distance.euclidean(point, center) for point in X_new_ori]\n",
    "            dist_std = (dist-np.min(dist))/(np.max(dist)-np.min(dist))\n",
    "            dist_scaled = dist_std * (np.max(dist)-np.min(dist)) + np.min(dist)\n",
    "            phi_list = 1/dist_scaled\n",
    "            z_list = np.random.binomial(1, phi_list, size=X_new_ori.shape)\n",
    "            # Random Dropout for X\n",
    "            X_new = X_new_ori*z_list/(1-phi_list)\n",
    "            \n",
    "            # Fit input learning algorithm with new data\n",
    "            reg = algo(X_new, Y_new)\n",
    "            # Predict Y using X test\n",
    "            pred = reg.predict(X_test)\n",
    "            \n",
    "            # Calculate MSE/MAD using the model obtained above\n",
    "            if criteria == \"MSE\":\n",
    "                error.append(mean_squared_error(Y_test, pred))\n",
    "            elif criteria == \"MAD\":\n",
    "                error.append(mean_absolute_error(Y_test, pred))\n",
    "            # Raise error if input is not MSE or MAD\n",
    "            else:\n",
    "                raise ValueError('Please input either MSE or MAD!')\n",
    "        \n",
    "        cv_error.append(np.mean(error))\n",
    "    \n",
    "    # Find optimal phi value that has the smallest CV error\n",
    "    phi_opt = phi_list[np.argmin(cv_error)]\n",
    "    \n",
    "    # Use the optimal phi value to train the predicted model\n",
    "    X_new_ori = np.repeat(X, M, axis=0)\n",
    "    Y_new = np.repeat(Y, M, axis=0)\n",
    "    \n",
    "    z = np.random.binomial(1, phi_opt, size=X_new_ori.shape)\n",
    "    X_new = X_new_ori*z/(1-phi_opt)\n",
    "\n",
    "    reg = algo(X_new, Y_new)\n",
    "    \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "84f68d05-2c05-4ce4-bd41-e7d392acb970",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = np.mean(X_new, axis=0)\n",
    "dist = [distance.euclidean(point, center) for point in X_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "502f8959-e568-49a9-8ad0-998c2970a1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.11635598696819"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a601c139-4abd-43f3-86e5-2c2811853c29",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "p < 0, p > 1 or p contains NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [120]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# dist_scaled = dist_std * (np.max(dist)-np.min(dist)) + np.min(dist)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m phi_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mdist_std\n\u001b[0;32m----> 6\u001b[0m z_list \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mmtrand.pyx:3386\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.binomial\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:359\u001b[0m, in \u001b[0;36mnumpy.random._common.check_array_constraint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: p < 0, p > 1 or p contains NaNs"
     ]
    }
   ],
   "source": [
    "center = np.mean(X_new, axis=0)\n",
    "dist = [distance.euclidean(point, center) for point in X_new]\n",
    "dist_std = (dist-np.min(dist))/(np.max(dist)-np.min(dist))\n",
    "dist_std = [d if d>0 else dfor d in dist_std]\n",
    "# dist_scaled = dist_std * (np.max(dist)-np.min(dist)) + np.min(dist)\n",
    "phi_list = 1/dist_std\n",
    "z_list = np.random.binomial(1, phi_list)\n",
    "# # Random Dropout for X\n",
    "# X_new = X_new_ori*z_list/(1-phi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "62644283-1db1-411c-90fa-18951753e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = np.mean(X_new, axis=0)\n",
    "dist = [distance.euclidean(point, center) for point in X_new]\n",
    "# dist_scaled = dist_std * (np.max(dist)-np.min(dist)) + np.min(dist)\n",
    "phi_list = dist/np.sum(dist)\n",
    "z_list = np.random.binomial(1, phi_list)\n",
    "# # Random Dropout for X\n",
    "# X_new = X_new_ori*z_list/(1-phi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b4d4a3fd-11aa-4d59-b3e3-09817a0777a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0cf608-ced7-4d16-a4af-c8f835e0f245",
   "metadata": {},
   "source": [
    "按照distance四等分（0-25，25-50...）,tune upper buond for probability (starting from 0.5 to 0.9), assign probability to 4 groups "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
